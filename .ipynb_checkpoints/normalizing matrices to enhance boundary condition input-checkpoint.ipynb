{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "This notebook contains the pseudo-algorithm of using finite difference methods to solve Black-Scholes Equation in order to get predictions for future option price.\n",
    "\n",
    "Main reference: *An ill-posed problem for the Black-Scholes equation for a profitable forecast of prices of stock options on real market data*\n",
    "\n",
    "### Current Problem\n",
    "The minizers using finite diff scheme -> tikhonov reg are tending to zero, regardless of the option/stock price."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A matrix is:\n",
      "[[ 1.13714669e+10 -2.27429338e+10  1.13714669e+10  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00 -1.11111111e-01\n",
      "   0.00000000e+00]\n",
      " [ 0.00000000e+00 -1.11111111e-01  0.00000000e+00  2.42455418e+10\n",
      "  -4.84910835e+10  2.42455418e+10  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00]\n",
      " [ 1.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00]\n",
      " [ 0.00000000e+00  1.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  1.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  1.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  1.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  1.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   1.00000000e+00]]\n",
      "\n",
      "f vector is:\n",
      "[ 0.          0.          8.5         8.70000013  8.90000025  9.00000049\n",
      " 10.10000038  9.35000137 11.55000019]\n",
      "\n",
      "The minimized result is\n",
      "[ 1.06140557e-32 -2.53620900e-32  1.06140557e-32  9.02541335e-22\n",
      " -1.80508267e-21  9.02541335e-22  0.00000000e+00 -1.03701560e-43\n",
      "  0.00000000e+00]\n"
     ]
    }
   ],
   "source": [
    "from eq_solver import num_solver as ns\n",
    "\n",
    "# This data comes from 531data/p1.csv:AAL US 1/18/2019 C40 Equity\n",
    "block = ns.DataBlock(today='10/19/2016',\n",
    "                  option_ask = [8.44999981, 8.55000019, 9.10000038],\n",
    "                  option_bid = [7.05000019, 7.8499999, 8.5],\n",
    "                  volatility = [39.456, 38.061, 37.096],\n",
    "                  stock_ask = 40.66,\n",
    "                  stock_bid = 40.65)\n",
    "\n",
    "block.af_system(3)\n",
    "\n",
    "print('A matrix is:')\n",
    "print(block.af[0])\n",
    "print()\n",
    "print('f vector is:')\n",
    "print(block.af[1])\n",
    "print()\n",
    "print('The minimized result is')\n",
    "print(block.reg(20, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem\n",
    "\n",
    "As you can see from the code above, the result from tikhonov regularization is incredibly small:\n",
    "\n",
    "$$ U = \\begin{bmatrix}\n",
    " 1.06140557e-32 & -2.53620900e-32 & 1.06140557e-32\\\\\n",
    " 9.02541335e-22 & -1.80508267e-21 & 9.02541335e-22\\\\\n",
    " 0.00000000e+00 & -1.03701560e-43 & 0.00000000e+00\\\\\n",
    "\\end{bmatrix} $$\n",
    "\n",
    "In order to solve the problem, I found the following code interesting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The true solution is:\n",
      "[-12.   4.   8.]\n",
      "\n",
      "Tikhonov result with beta = 0.01 and scale = 1:\n",
      "[-11.53735218   3.84616483   7.80656087]\n",
      "\n",
      "Tikhonov result with beta = 0.01 and scale = 10:\n",
      "[-11.64934312   3.84505601   7.80545205]\n",
      "\n",
      "Tikhonov result with beta = 0.01 and scale = 100:\n",
      "[-11.65047401   3.84504481   7.80544085]\n",
      "\n",
      "Tikhonov result with beta = 0.01 and scale = 1000:\n",
      "[-11.65048532   3.8450447    7.80544074]\n",
      "\n",
      "Tikhonov result with beta = 0.01 and scale = 10000:\n",
      "[-11.65048447   3.84504423   7.80544025]\n",
      "\n",
      "Tikhonov result with beta = 0.01 and scale = 100000:\n",
      "[-11.65053463   3.84506974   7.80546488]\n",
      "\n",
      "Tikhonov result with beta = 0.01 and scale = 1000000:\n",
      "[-11.65173268   3.84568747   7.80604521]\n",
      "\n",
      "Tikhonov result with beta = 0.01 and scale = 10000000:\n",
      "[-11.24438268   3.65296057   7.59142211]\n",
      "\n",
      "Tikhonov result with beta = 0.01 and scale = 100000000:\n",
      "[1.33333333e-16 1.33333333e-16 1.33333333e-16]\n",
      "\n",
      "Tikhonov result with beta = 0.01 and scale = 1000000000:\n",
      "[1.33333333e-18 1.33333333e-18 1.33333333e-18]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Here's the test for the tikhonov regularization.\n",
    "import numpy as np\n",
    "\n",
    "scale = 1\n",
    "x = np.array([[scale, scale, scale], [0, 1, 0], [0, 0, 1]])\n",
    "f = np.array([0, 4, 8])\n",
    "print('The true solution is:')\n",
    "print(ns.tikhonov(x, f, 0))\n",
    "print()\n",
    "\n",
    "while scale < 10 ** 10:\n",
    "    x = np.array([[scale, scale, scale], [0, 1, 0], [0, 0, 1]])\n",
    "\n",
    "    print(f'Tikhonov result with beta = 0.01 and scale = {scale}:')\n",
    "    print(ns.tikhonov(x, f, 0.01))\n",
    "    print()\n",
    "    scale *= 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explanation:\n",
    "From the example shown above, we can conclude that even if two matrices are mathematically equivalent, such as\n",
    "\n",
    "$$ X = \\begin{bmatrix}\n",
    " 1 & 1 & 1\\\\\n",
    " 0 & 1 & 0\\\\\n",
    " 0 & 0 & 1\n",
    "\\end{bmatrix}$$\n",
    "\n",
    "and \n",
    "\n",
    "$$ X' = \\begin{bmatrix}\n",
    " 100000 & 100000 & 100000\\\\\n",
    " 0 & 1 & 0\\\\\n",
    " 0 & 0 & 1\n",
    "\\end{bmatrix};$$\n",
    "\n",
    "\n",
    "are not necessarily equivalent in the tikhonov regularization.\n",
    "\n",
    "It is because of the tikhonov reg parameter treats every row equivalently, as in the solution\n",
    "\n",
    "$$ U = (\\mathcal{A}^T A + \\beta I_{MN})^{-1} \\mathcal{A}^T f.$$\n",
    "\n",
    "However, in the `num_solver`, the matrix is having incredibly large indices from the Black Scholes Equation as we can see from the results above (like `[2.42455418e+10, -4.84910835e+10,  2.42455418e+10]`).\n",
    "\n",
    "### Potential Solution\n",
    "Normalize each row vector might be a feasible way. For example, the matrix $X'$ will be normalized to\n",
    "\n",
    "$$ X'_n = \\begin{bmatrix}\n",
    " \\sqrt{1/3} & \\sqrt{1/3} & \\sqrt{1/3} \\\\\n",
    " 0 & 1 & 0\\\\\n",
    " 0 & 0 & 1\n",
    "\\end{bmatrix};$$\n",
    "\n",
    "Now we can test on this normalized matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New tikhonov result with beta = 0.01 and scale = 0.5773502691896257:\n",
      "[-11.31755164   3.84834107   7.80873711]\n",
      "While the true solution is\n",
      "[-12.   4.   8.]\n"
     ]
    }
   ],
   "source": [
    "# Test X'_n.\n",
    "\n",
    "import math\n",
    "\n",
    "scale = math.sqrt(1/3)\n",
    "x = np.array([[scale, scale, scale], [0, 1, 0], [0, 0, 1]])\n",
    "f = np.array([0, 4, 8])\n",
    "print(f'New tikhonov result with beta = 0.01 and scale = {scale}:')\n",
    "print(ns.tikhonov(x, f, 0.01))\n",
    "print('While the true solution is')\n",
    "print(ns.tikhonov(x, f, 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can apply it to the real data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The norm vector is:\n",
      "[2.78542916e+10 5.93892058e+10 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00]\n",
      "\n",
      "New Tikhonov Result is\n",
      "[ 8.50000000e+00  8.70000013e+00  8.90000025e+00  9.00000049e+00\n",
      "  9.55000044e+00  1.01000004e+01  9.35000137e+00 -5.14638402e-15\n",
      "  1.15500002e+01]\n"
     ]
    }
   ],
   "source": [
    "matrix = block.af[0]\n",
    "f = block.af[1]\n",
    "\n",
    "norm_value = np.linalg.norm(matrix, axis = 1, ord=2)\n",
    "print('The norm vector is:')\n",
    "print(norm_value)\n",
    "print()\n",
    "norm_matrix = matrix / norm_value[:,None]\n",
    "norm_f = f / norm_value\n",
    "\n",
    "print('New Tikhonov Result is')\n",
    "print(ns.tikhonov(norm_matrix, norm_f, 0.01))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ U_n = \\begin{bmatrix}\n",
    " 8.42 & 8.61 & 8.81 \\\\\n",
    " 8.86 & 9.27 & 9.95 \\\\\n",
    " 9.26 & 0.00 &10.14 \\\\\n",
    "\\end{bmatrix} $$\n",
    "\n",
    "Some better data. Note that $0.00$ there, it still might be a problem, but it is definitely better than before.\n",
    "\n",
    "Guess:\n",
    "- The tikhonov still causes the 0 term.\n",
    "- The 0 will disappear as the grid_count increases."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:mathpy]",
   "language": "python",
   "name": "conda-env-mathpy-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
